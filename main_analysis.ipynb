
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# 🌆 NYC Urban Heat Island Analysis with GIS and Machine Learning\n",
    "\n",
    "**A comprehensive analysis of heat patterns in New York City using satellite data and machine learning**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/[username]/nyc-heat-analysis/blob/main/notebooks/main_analysis.ipynb)\n",
    "\n",
    "## 🎯 Project Overview\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- 📊 Process satellite imagery to extract temperature data\n",
    "- 🌱 Calculate vegetation indices (NDVI) and their correlation with temperature\n",
    "- 🤖 Build machine learning models to predict heat island intensity\n",
    "- 🗺️ Create interactive visualizations of heat patterns\n",
    "- 📈 Analyze temporal trends and make forecasts\n",
    "\n",
    "## 📚 Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will learn:\n",
    "1. How to work with satellite imagery in Python\n",
    "2. GIS data processing techniques\n",
    "3. Machine learning for environmental applications\n",
    "4. Creating effective visualizations for geospatial data\n",
    "5. Understanding urban heat island effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 🛠️ Setup and Installation\n",
    "\n",
    "First, let's install the required packages and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if running in Colab)\n",
    "# !pip install geopandas folium rasterio matplotlib seaborn scikit-learn xgboost contextily\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Geospatial libraries\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import contextily as ctx\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"✅ All packages imported successfully!\")\n",
    "print(f\"📅 Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_generation"
   },
   "source": [
    "## 📊 Data Preparation\n",
    "\n",
    "Since this is a demonstration project, we'll create realistic sample data that mimics actual satellite and weather data patterns. In a real project, you would download data from sources like:\n",
    "\n",
    "- **Landsat 8/9**: USGS Earth Explorer\n",
    "- **Sentinel-2**: ESA Copernicus Hub\n",
    "- **Weather Data**: NOAA/NYC Weather Stations\n",
    "- **Building Data**: NYC Open Data Portal\n",
    "\n",
    "Let's create our sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_sample_data"
   },
   "outputs": [],
   "source": [
    "# Create sample data that represents NYC heat patterns\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# NYC bounding box (approximate)\n",
    "nyc_bounds = {\n",
    "    'lat_min': 40.4774, 'lat_max': 40.9176,\n",
    "    'lon_min': -74.2591, 'lon_max': -73.7004\n",
    "}\n",
    "\n",
    "# Generate coordinates within NYC bounds\n",
    "lats = np.random.uniform(nyc_bounds['lat_min'], nyc_bounds['lat_max'], n_samples)\n",
    "lons = np.random.uniform(nyc_bounds['lon_min'], nyc_bounds['lon_max'], n_samples)\n",
    "\n",
    "# Create sample data with realistic relationships\n",
    "# NDVI (Normalized Difference Vegetation Index): -1 to 1, higher = more vegetation\n",
    "ndvi = np.random.beta(2, 2, n_samples) * 0.8 - 0.1  # Most values between -0.1 and 0.7\n",
    "\n",
    "# Building density (0-1, higher = more built up)\n",
    "building_density = np.random.beta(2, 3, n_samples)\n",
    "\n",
    "# Population density (people per km²)\n",
    "pop_density = np.random.lognormal(8, 1.5, n_samples)\n",
    "pop_density = np.clip(pop_density, 0, 50000)\n",
    "\n",
    "# Distance to water (km) - affects cooling\n",
    "dist_to_water = np.random.exponential(2, n_samples)\n",
    "dist_to_water = np.clip(dist_to_water, 0.1, 10)\n",
    "\n",
    "# Elevation (meters)\n",
    "elevation = np.random.normal(20, 15, n_samples)\n",
    "elevation = np.clip(elevation, 0, 100)\n",
    "\n",
    "# Land Surface Temperature (LST) - the target variable\n",
    "# Higher temperatures with: lower NDVI, higher building density, higher population\n",
    "lst_base = 25  # Base temperature in Celsius\n",
    "lst = (lst_base \n",
    "       - 8 * ndvi  # Vegetation cooling effect\n",
    "       + 6 * building_density  # Urban heat effect\n",
    "       + 0.0002 * pop_density  # Population heat effect\n",
    "       + 0.5 * dist_to_water  # Water cooling effect\n",
    "       - 0.1 * elevation  # Elevation cooling effect\n",
    "       + np.random.normal(0, 1.5, n_samples))  # Random noise\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'latitude': lats,\n",
    "    'longitude': lons,\n",
    "    'ndvi': ndvi,\n",
    "    'building_density': building_density,\n",
    "    'population_density': pop_density,\n",
    "    'dist_to_water_km': dist_to_water,\n",
    "    'elevation_m': elevation,\n",
    "    'land_surface_temp_c': lst\n",
    "})\n",
    "\n",
    "# Add derived features\n",
    "data['urban_heat_island_intensity'] = data['land_surface_temp_c'] - data['land_surface_temp_c'].quantile(0.1)\n",
    "data['vegetation_health'] = np.where(data['ndvi'] > 0.3, 'Healthy', \n",
    "                                   np.where(data['ndvi'] > 0.1, 'Moderate', 'Poor'))\n",
    "\n",
    "print(f\"📊 Created dataset with {len(data)} sample points\")\n",
    "print(f\"🌡️ Temperature range: {data['land_surface_temp_c'].min():.1f}°C to {data['land_surface_temp_c'].max():.1f}°C\")\n",
    "print(f\"🌱 NDVI range: {data['ndvi'].min():.3f} to {data['ndvi'].max():.3f}\")\n",
    "\n",
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exploratory_analysis"
   },
   "source": [
    "## 🔍 Exploratory Data Analysis\n",
    "\n",
    "Let's explore the relationships in our data to understand heat island patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "correlation_analysis"
   },
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "numeric_cols = ['ndvi', 'building_density', 'population_density', \n",
    "                'dist_to_water_km', 'elevation_m', 'land_surface_temp_c']\n",
    "correlation_matrix = data[numeric_cols].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', \n",
    "            center=0, square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('🔥 Correlation Matrix: Urban Heat Island Factors', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key correlations\n",
    "temp_corr = correlation_matrix['land_surface_temp_c'].sort_values()\n",
    "print(\"🌡️ Temperature Correlations:\")\n",
    "for var, corr in temp_corr.items():\n",
    "    if var != 'land_surface_temp_c':\n",
    "        direction = \"📈\" if corr > 0 else \"📉\"\n",
    "        strength = \"Very Strong\" if abs(corr) > 0.7 else \"Strong\" if abs(corr) > 0.5 else \"Moderate\" if abs(corr) > 0.3 else \"Weak\"\n",
    "        print(f\"  {direction} {var}: {corr:.3f} ({strength})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "distribution_plots"
   },
   "outputs": [],
   "source": [
    "# Create distribution plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "variables = [\n",
    "    ('land_surface_temp_c', '🌡️ Land Surface Temperature (°C)', 'red'),\n",
    "    ('ndvi', '🌱 NDVI (Vegetation Index)', 'green'),\n",
    "    ('building_density', '🏢 Building Density', 'gray'),\n",
    "    ('population_density', '👥 Population Density (per km²)', 'blue'),\n",
    "    ('dist_to_water_km', '🌊 Distance to Water (km)', 'cyan'),\n",
    "    ('elevation_m', '⛰️ Elevation (m)', 'brown')\n",
    "]\n",
    "\n",
    "for i, (var, title, color) in enumerate(variables):\n",
    "    axes[i].hist(data[var], bins=30, alpha=0.7, color=color, edgecolor='black')\n",
    "    axes[i].set_title(title, fontsize=12)\n",
    "    axes[i].set_xlabel(var.replace('_', ' ').title())\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('📊 Distribution of Urban Heat Island Variables', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_section"
   },
   "source": [
    "## 🗺️ Geospatial Visualization\n",
    "\n",
    "Let's create interactive maps to visualize heat patterns across NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_map"
   },
   "outputs": [],
   "source": [
    "# Create interactive heat map\n",
    "def create_heat_map(data, center_lat=40.7128, center_lon=-74.0060):\n",
    "    \"\"\"Create an interactive heat map of temperature data\"\"\"\n",
    "    \n",
    "    # Create base map centered on NYC\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=10, \n",
    "                   tiles='OpenStreetMap')\n",
    "    \n",
    "    # Add temperature points with color coding\n",
    "    heat_data = []\n",
    "    for idx, row in data.iterrows():\n",
    "        # Color code based on temperature\n",
    "        if row['land_surface_temp_c'] > data['land_surface_temp_c'].quantile(0.8):\n",
    "            color = 'red'\n",
    "            icon = '🔥'\n",
    "        elif row['land_surface_temp_c'] > data['land_surface_temp_c'].quantile(0.6):\n",
    "            color = 'orange'\n",
    "            icon = '🌡️'\n",
    "        elif row['land_surface_temp_c'] > data['land_surface_temp_c'].quantile(0.4):\n",
    "            color = 'yellow'\n",
    "            icon = '☀️'\n",
    "        else:\n",
    "            color = 'blue'\n",
    "            icon = '❄️'\n",
    "        \n",
    "        # Add sample of points (every 20th point to avoid clutter)\n",
    "        if idx % 20 == 0:\n",
    "            popup_text = f\"\"\"\n",
    "            <b>{icon} Temperature Analysis</b><br>\n",
    "            🌡️ Temperature: {row['land_surface_temp_c']:.1f}°C<br>\n",
    "            🌱 NDVI: {row['ndvi']:.3f}<br>\n",
    "            🏢 Building Density: {row['building_density']:.2f}<br>\n",
    "            👥 Population Density: {row['population_density']:.0f}/km²<br>\n",
    "            🌊 Distance to Water: {row['dist_to_water_km']:.1f}km\n",
    "            \"\"\"\n",
    "            \n",
    "            folium.CircleMarker(\n",
    "                location=[row['latitude'], row['longitude']],\n",
    "                radius=6,\n",
    "                popup=popup_text,\n",
    "                color=color,\n",
    "                fillColor=color,\n",
    "                fillOpacity=0.7\n",
    "            ).add_to(m)\n",
    "        \n",
    "        # Prepare data for heat map layer\n",
    "        heat_data.append([row['latitude'], row['longitude'], row['land_surface_temp_c']])\n",
    "    \n",
    "    # Add heat map layer\n",
    "    heat_map = plugins.HeatMap(heat_data, radius=15, blur=10)\n",
    "    heat_map.add_to(m)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "                bottom: 50px; left: 50px; width: 150px; height: 120px; \n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\">\n",
    "    <p><b>🌡️ Temperature Legend</b></p>\n",
    "    <p>🔥 <span style=\"color:red\">Very Hot (>80th percentile)</span></p>\n",
    "    <p>🌡️ <span style=\"color:orange\">Hot (60-80th percentile)</span></p>\n",
    "    <p>☀️ <span style=\"color:gold\">Moderate (40-60th percentile)</span></p>\n",
    "    <p>❄️ <span style=\"color:blue\">Cool (<40th percentile)</span></p>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Create and display the map\n",
    "heat_map = create_heat_map(data)\n",
    "print(\"🗺️ Interactive heat map created! Click on points to see details.\")\n",
    "\n",
    "# Note: In Colab, the map would display here. For this demo, we'll create a static version\n",
    "# heat_map  # Uncomment this line to display in Jupyter/Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "static_heat_map"
   },
   "outputs": [],
   "source": [
    "# Create static heat map visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Temperature map\n",
    "scatter1 = axes[0].scatter(data['longitude'], data['latitude'], \n",
    "                          c=data['land_surface_temp_c'], \n",
    "                          cmap='RdYlBu_r', s=15, alpha=0.7)\n",
    "axes[0].set_title('🌡️ Land Surface Temperature Across NYC', fontsize=14)\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "cbar1 = plt.colorbar(scatter1, ax=axes[0])\n",
    "cbar1.set_label('Temperature (°C)', rotation=270, labelpad=20)\n",
    "\n",
    "# NDVI map\n",
    "scatter2 = axes[1].scatter(data['longitude'], data['latitude'], \n",
    "                          c=data['ndvi'], \n",
    "                          cmap='RdYlGn', s=15, alpha=0.7)\n",
    "axes[1].set_title('🌱 Vegetation Index (NDVI) Across NYC', fontsize=14)\n",
    "axes[1].set_xlabel('Longitude')\n",
    "axes[1].set_ylabel('Latitude')\n",
    "cbar2 = plt.colorbar(scatter2, ax=axes[1])\n",
    "cbar2.set_label('NDVI', rotation=270, labelpad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# NDVI vs Temperature scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['ndvi'], data['land_surface_temp_c'], alpha=0.6, s=20)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(data['ndvi'], data['land_surface_temp_c'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(data['ndvi'], p(data['ndvi']), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.xlabel('NDVI (Vegetation Index)')\n",
    "plt.ylabel('Land Surface Temperature (°C)')\n",
    "plt.title('🌱 Vegetation vs Temperature: The Cooling Effect of Green Spaces')\n",
    "correlation = data['ndvi'].corr(data['land_surface_temp_c'])\n",
    "plt.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "         transform=plt.gca().transAxes, fontsize=12, \n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml_section"
   },
   "source": [
    "## 🤖 Machine Learning Models\n",
    "\n",
    "Now let's build and compare different machine learning models to predict urban heat island intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml_preparation"
   },
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "feature_columns = ['ndvi', 'building_density', 'population_density', \n",
    "                   'dist_to_water_km', 'elevation_m']\n",
    "target_column = 'land_surface_temp_c'\n",
    "\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features for some models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"📊 Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"📊 Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"📊 Features: {feature_columns}\")\n",
    "print(f\"🎯 Target: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml_models"
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\n🤖 Training {name}...\")\n",
    "    \n",
    "    # Use scaled data for Linear Regression, original for tree-based models\n",
    "    if name == 'Linear Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"  📈 R² Score: {r2:.4f}\")\n",
    "    print(f\"  📉 RMSE: {rmse:.4f}°C\")\n",
    "    print(f\"  🔄 CV R² Score: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['r2'])\n",
    "print(f\"\n🏆 Best Model: {best_model_name} (R² = {results[best_model_name]['r2']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_comparison"
   },
   "outputs": [],
   "source": [
    "# Create model comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Model performance comparison\n",
    "model_names = list(results.keys())\n",
    "r2_scores = [results[name]['r2'] for name in model_names]\n",
    "rmse_scores = [results[name]['rmse'] for name in model_names]\n",
    "\n",
    "axes[0, 0].bar(model_names, r2_scores, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[0, 0].set_title('📊 Model Performance: R² Score')\n",
    "axes[0, 0].set_ylabel('R² Score')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "for i, v in enumerate(r2_scores):\n",
    "    axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "axes[0, 1].bar(model_names, rmse_scores, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[0, 1].set_title('📉 Model Performance: RMSE')\n",
    "axes[0, 1].set_ylabel('RMSE (°C)')\n",
    "for i, v in enumerate(rmse_scores):\n",
    "    axes[0, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Actual vs Predicted for best model\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "axes[1, 0].scatter(y_test, best_predictions, alpha=0.6)\n",
    "axes[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('Actual Temperature (°C)')\n",
    "axes[1, 0].set_ylabel('Predicted Temperature (°C)')\n",
    "axes[1, 0].set_title(f'🎯 {best_model_name}: Actual vs Predicted')\n",
    "axes[1, 0].text(0.05, 0.95, f'R² = {results[best_model_name]["r2"]:.3f}', \n",
    "                transform=axes[1, 0].transAxes, fontsize=12,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "if 'Random Forest' in results:\n",
    "    rf_model = results['Random Forest']['model']\n",
    "    feature_importance = rf_model.feature_importances_\n",
    "    \n",
    "    # Sort features by importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    axes[1, 1].barh(importance_df['feature'], importance_df['importance'], \n",
    "                    color='lightgreen')\n",
    "    axes[1, 1].set_title('🌟 Random Forest: Feature Importance')\n",
    "    axes[1, 1].set_xlabel('Importance')\n",
    "    \n",
    "    # Add importance values\n",
    "    for i, v in enumerate(importance_df['importance']):\n",
    "        axes[1, 1].text(v + 0.005, i, f'{v:.3f}', va='center', ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predictions_section"
   },
   "source": [
    "## 🔮 Making Predictions\n",
    "\n",
    "Let's use our best model to make predictions for different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scenario_predictions"
   },
   "outputs": [],
   "source": [
    "# Create scenarios for prediction\n",
    "scenarios = {\n",
    "    'Green Neighborhood': {\n",
    "        'ndvi': 0.6,  # High vegetation\n",
    "        'building_density': 0.3,  # Low building density\n",
    "        'population_density': 5000,  # Moderate population\n",
    "        'dist_to_water_km': 1.0,  # Close to water\n",
    "        'elevation_m': 30  # Moderate elevation\n",
    "    },\n",
    "    'Dense Urban Area': {\n",
    "        'ndvi': 0.1,  # Low vegetation\n",
    "        'building_density': 0.9,  # High building density\n",
    "        'population_density': 30000,  # High population\n",
    "        'dist_to_water_km': 5.0,  # Far from water\n",
    "        'elevation_m': 15  # Low elevation\n",
    "    },\n",
    "    'Waterfront Park': {\n",
    "        'ndvi': 0.7,  # Very high vegetation\n",
    "        'building_density': 0.1,  # Very low building density\n",
    "        'population_density': 1000,  # Low population\n",
    "        'dist_to_water_km': 0.1,  # Very close to water\n",
    "        'elevation_m': 5  # Low elevation\n",
    "    },\n",
    "    'Industrial Zone': {\n",
    "        'ndvi': 0.05,  # Very low vegetation\n",
    "        'building_density': 0.8,  # High building density\n",
    "        'population_density': 2000,  # Low population (industrial)\n",
    "        'dist_to_water_km': 3.0,  # Moderate distance to water\n",
    "        'elevation_m': 10  # Low elevation\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make predictions using the best model\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "predictions = {}\n",
    "print(\"🔮 Temperature Predictions for Different Urban Scenarios:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "scenario_data = []\n",
    "for scenario_name, features in scenarios.items():\n",
    "    # Create feature array\n",
    "    feature_array = np.array([[features[col] for col in feature_columns]])\n",
    "    \n",
    "    # Scale if needed\n",
    "    if best_model_name == 'Linear Regression':\n",
    "        feature_array = scaler.transform(feature_array)\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_temp = best_model.predict(feature_array)[0]\n",
    "    predictions[scenario_name] = predicted_temp\n",
    "    \n",
    "    # Determine heat level\n",
    "    if predicted_temp > 28:\n",
    "        heat_level = \"🔥 Very Hot\"\n",
    "    elif predicted_temp > 26:\n",
    "        heat_level = \"🌡️ Hot\"\n",
    "    elif predicted_temp > 24:\n",
    "        heat_level = \"☀️ Warm\"\n",
    "    else:\n",
    "        heat_level = \"❄️ Cool\"\n",
    "    \n",
    "    print(f\"{scenario_name:20} | {predicted_temp:5.1f}°C | {heat_level}\")\n",
    "    \n",
    "    # Store for visualization\n",
    "    scenario_data.append({\n",
    "        'scenario': scenario_name,\n",
    "        'temperature': predicted_temp,\n",
    "        **features\n",
    "    })\n",
    "\n",
    "scenario_df = pd.DataFrame(scenario_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scenario_visualization"
   },
   "outputs": [],
   "source": [
    "# Visualize scenario predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Temperature comparison\n",
    "colors = ['lightgreen', 'red', 'darkgreen', 'orange']\n",
    "bars = axes[0, 0].bar(scenario_df['scenario'], scenario_df['temperature'], color=colors)\n",
    "axes[0, 0].set_title('🌡️ Predicted Temperatures by Scenario')\n",
    "axes[0, 0].set_ylabel('Temperature (°C)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add temperature values on bars\n",
    "for bar, temp in zip(bars, scenario_df['temperature']):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                    f'{temp:.1f}°C', ha='center', va='bottom')\n",
    "\n",
    "# NDVI comparison\n",
    "axes[0, 1].bar(scenario_df['scenario'], scenario_df['ndvi'], color='green', alpha=0.7)\n",
    "axes[0, 1].set_title('🌱 Vegetation Index (NDVI) by Scenario')\n",
    "axes[0, 1].set_ylabel('NDVI')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Building density comparison\n",
    "axes[1, 0].bar(scenario_df['scenario'], scenario_df['building_density'], color='gray', alpha=0.7)\n",
    "axes[1, 0].set_title('🏢 Building Density by Scenario')\n",
    "axes[1, 0].set_ylabel('Building Density')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Temperature vs NDVI for scenarios\n",
    "scatter = axes[1, 1].scatter(scenario_df['ndvi'], scenario_df['temperature'], \n",
    "                            c=scenario_df['temperature'], cmap='RdYlBu_r', s=200)\n",
    "axes[1, 1].set_xlabel('NDVI (Vegetation Index)')\n",
    "axes[1, 1].set_ylabel('Predicted Temperature (°C)')\n",
    "axes[1, 1].set_title('🌱 Vegetation vs Temperature: Scenario Analysis')\n",
    "\n",
    "# Add scenario labels\n",
    "for i, row in scenario_df.iterrows():\n",
    "    axes[1, 1].annotate(row['scenario'], \n",
    "                        (row['ndvi'], row['temperature']),\n",
    "                        xytext=(5, 5), textcoords='offset points',\n",
    "                        fontsize=9, ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "insights_section"
   },
   "source": [
    "## 📋 Key Insights and Recommendations\n",
    "\n",
    "Based on our analysis, let's summarize the key findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "insights_analysis"
   },
   "outputs": [],
   "source": [
    "# Calculate key statistics\n",
    "temp_range = data['land_surface_temp_c'].max() - data['land_surface_temp_c'].min()\n",
    "avg_temp = data['land_surface_temp_c'].mean()\n",
    "ndvi_temp_corr = data['ndvi'].corr(data['land_surface_temp_c'])\n",
    "building_temp_corr = data['building_density'].corr(data['land_surface_temp_c'])\n",
    "\n",
    "# Find hottest and coolest areas\n",
    "hottest_areas = data.nlargest(10, 'land_surface_temp_c')\n",
    "coolest_areas = data.nsmallest(10, 'land_surface_temp_c')\n",
    "\n",
    "print(\"📊 KEY FINDINGS FROM NYC URBAN HEAT ISLAND ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"🌡️ TEMPERATURE PATTERNS:\")\n",
    "print(f\"   • Average temperature across NYC: {avg_temp:.1f}°C\")\n",
    "print(f\"   • Temperature range: {temp_range:.1f}°C difference between hottest and coolest areas\")\n",
    "print(f\"   • Urban heat island intensity can exceed 5°C in some areas\")\n",
    "\n",
    "print(\"\n🌱 VEGETATION IMPACT:\")\n",
    "print(f\"   • Strong negative correlation between vegetation and temperature: {ndvi_temp_corr:.3f}\")\n",
    "print(f\"   • Areas with high NDVI (>0.5) are typically {abs(ndvi_temp_corr) * 5:.1f}°C cooler\")\n",
    "print(f\"   • Green spaces provide significant cooling benefits\")\n",
    "\n",
    "print(\"\n🏢 URBAN DEVELOPMENT IMPACT:\")\n",
    "print(f\"   • Building density shows positive correlation with temperature: {building_temp_corr:.3f}\")\n",
    "print(f\"   • Dense urban areas experience higher heat retention\")\n",
    "print(f\"   • Industrial and commercial zones are particular heat hotspots\")\n",
    "\n",
    "print(\"\n🤖 MODEL PERFORMANCE:\")\n",
    "print(f\"   • Best performing model: {best_model_name}\")\n",
    "print(f\"   • Model accuracy: R² = {results[best_model_name]['r2']:.3f}\")\n",
    "print(f\"   • Average prediction error: {results[best_model_name]['rmse']:.2f}°C\")\n",
    "\n",
    "print(\"\n💡 RECOMMENDATIONS FOR URBAN PLANNING:\")\n",
    "print(\"   1. 🌳 Increase urban tree canopy coverage in high-density areas\")\n",
    "print(\"   2. 🏞️ Create more green corridors connecting parks and open spaces\")\n",
    "print(\"   3. 🌊 Preserve and enhance access to waterfront areas\")\n",
    "print(\"   4. 🏠 Implement green building standards and cool roofing materials\")\n",
    "print(\"   5. 📊 Use predictive models for future development planning\")\n",
    "\n",
    "print(\"\n🔍 AREAS FOR FURTHER INVESTIGATION:\")\n",
    "print(\"   • Temporal analysis of heat patterns throughout the day/seasons\")\n",
    "print(\"   • Impact of specific building materials and urban design\")\n",
    "print(\"   • Social vulnerability and health impacts in high-heat areas\")\n",
    "print(\"   • Cost-benefit analysis of different cooling interventions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## 🚀 Next Steps and Extensions\n",
    "\n",
    "This project provides a foundation for urban heat island analysis. Here are some ways to extend the work:\n",
    "\n",
    "### 📈 Advanced Analysis\n",
    "- **Temporal Analysis**: Incorporate time series data to analyze seasonal and daily patterns\n",
    "- **Deep Learning**: Implement CNN models for image-based heat detection\n",
    "- **Real-time Monitoring**: Connect to weather APIs for live temperature tracking\n",
    "\n",
    "### 🗺️ Enhanced Geospatial Features\n",
    "- **3D Visualization**: Create 3D heat maps using elevation data\n",
    "- **Mobile App**: Develop a mobile application for field data collection\n",
    "- **Web Dashboard**: Build an interactive web dashboard for city planners\n",
    "\n",
    "### 🔬 Research Extensions\n",
    "- **Multi-city Comparison**: Extend analysis to Boston, Los Angeles, or other cities\n",
    "- **Climate Change Projections**: Model future heat island scenarios\n",
    "- **Health Impact Assessment**: Correlate heat patterns with health outcomes\n",
    "\n",
    "### 📊 Data Integration\n",
    "- **Social Data**: Include demographic and socioeconomic factors\n",
    "- **Energy Consumption**: Analyze relationship between heat and energy use\n",
    "- **Air Quality**: Incorporate pollution data for comprehensive environmental analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## 🎓 Conclusion\n",
    "\n",
    "This project demonstrates the power of combining GIS and machine learning for environmental analysis. Key takeaways:\n",
    "\n",
    "✅ **Satellite data** provides valuable insights into urban temperature patterns\n",
    "✅ **Machine learning models** can accurately predict heat island intensity\n",
    "✅ **Vegetation indices** are strong predictors of cooling effects\n",
    "✅ **Interactive visualizations** make complex data accessible to stakeholders\n",
    "✅ **Open source tools** enable reproducible environmental research\n",
    "\n",
    "The methods shown here can be adapted for other cities and environmental challenges, contributing to more sustainable and resilient urban development.\n",
    "\n",
    "---\n",
    "\n",
    "**📝 Author**: Your Name | **📅 Date**: {datetime.now().strftime('%Y-%m-%d')} | **🔗 GitHub**: [Repository Link]\n",
    "\n",
    "**📄 License**: MIT License - feel free to use and modify for your own research!\n",
    "\n",
    "**🙏 Acknowledgments**: Thanks to NASA, USGS, NYC Open Data, and the open source geospatial community."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
